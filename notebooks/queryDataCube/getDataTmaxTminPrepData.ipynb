{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initializeZarrConnection( s3Path: str\n",
    "                             ,s3 \n",
    "                             )->xr.Dataset:\n",
    "    \"\"\"\n",
    "    Initializes a Zarr connection using an S3 path and S3 client.\n",
    "\n",
    "    Parameters:\n",
    "    - s3Path (str): The S3 path to the Zarr store.\n",
    "    - s3: An S3 client object.\n",
    "\n",
    "    Returns:\n",
    "    - xarray.Dataset: The Zarr data as an xarray dataset.\n",
    "    \"\"\"\n",
    "    zarrMap = s3fs.S3Map(root=s3Path, s3=s3, check=False)\n",
    "    zarrData = xr.open_zarr(store=zarrMap, consolidated=True)\n",
    "    return zarrData\n",
    "\n",
    "def locationDataframe(zarrData,lat,lon) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts location-based data from a Zarr dataset and returns it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - zarrData (xarray.Dataset): The Zarr dataset containing spatial data.\n",
    "    - lat (float): Latitude value for the desired location.\n",
    "    - lon (float): Longitude value for the desired location.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the extracted data for the specified location.\n",
    "    \"\"\"\n",
    "    zarrData = zarrData.sel(lat = lat\n",
    "                            , lon = lon\n",
    "                            , method='nearest')\n",
    "    df = zarrData.to_dataframe().reset_index()\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = lon\n",
    "    return df\n",
    "\n",
    "def generateCSVLocationVariables(lat: float\n",
    "                                 ,lon: float\n",
    "                                 ,outputPath:str = None\n",
    "                                 ):\n",
    "    \"\"\"\n",
    "    Generates a CSV file containing climate variables for a specific location (latitude, longitude).\n",
    "\n",
    "    Parameters:\n",
    "    - lat (float): Latitude value for the desired location.\n",
    "    - lon (float): Longitude value for the desired location.\n",
    "    - outputPath (str, optional): Path to the directory where the CSV file will be saved. If not provided,\n",
    "      the CSV file will be saved in the current working directory.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    generateCSVLocationVariables(lat=35.0, lon=-120.0, outputPath='/path/to/output/')\n",
    "    ```\n",
    "\n",
    "    Note:\n",
    "    - The function utilizes the `initializeZarrConnection` and `locationDataframe` functions to extract\n",
    "      climate data for the specified location from Zarr datasets.\n",
    "    - The resulting CSV file includes columns for time, Julian day ('@DATE'), maximum temperature ('TMAX'),\n",
    "      minimum temperature ('TMIN'), and precipitation ('RAIN').\n",
    "    - The CSV file is saved with a ';' delimiter and rounded to one decimal place.\n",
    "    \"\"\"\n",
    "    _lat = lat\n",
    "    _lon = lon\n",
    "    global rangeOfDates\n",
    "    tmaxData = initializeZarrConnection(agera5Tmax,s3)\n",
    "    tminData = initializeZarrConnection(agera5Tmin,s3)\n",
    "    prepData = initializeZarrConnection(chirpsPrecipitation,s3)\n",
    "    tmaxData = tmaxData.sel( time = rangeOfDates )\n",
    "    tminData = tminData.sel( time = rangeOfDates )\n",
    "    prepData = prepData.sel( time = rangeOfDates )\n",
    "    df1 = locationDataframe(tmaxData,_lat,_lon )\n",
    "    df2 = locationDataframe(tminData,_lat,_lon )\n",
    "    df3 = locationDataframe(prepData,_lat,_lon )\n",
    "    df1['j_day'] = df1.time.apply(lambda x: x.strftime('%y') +x.strftime('%j') )\n",
    "    alldf = df1.join(df2.set_index(['time','lat','lon']), on = ['time','lat','lon'])\n",
    "    alldf = alldf.join(df3.set_index(['time','lat','lon']), on = ['time','lat','lon'])\n",
    "    alldf = alldf[['time','j_day','Temperature_Air_2m_Min_24h','Temperature_Air_2m_Max_24h','precipitation']]\n",
    "    alldf = alldf.rename(columns={'j_day':'@DATE'\n",
    "                ,'Temperature_Air_2m_Max_24h': 'TMAX'\n",
    "                ,'Temperature_Air_2m_Min_24h': 'TMIN'\n",
    "                ,'precipitation':'RAIN'})\n",
    "\n",
    "    alldf = alldf.round(decimals=1)\n",
    "    if outputPath:\n",
    "        alldf.to_csv(outputPath+'data_'+str(_lat)+\"_\"+str(lon)+'.csv',sep=';',index=False)\n",
    "    else:\n",
    "        alldf.to_csv('data_'+str(_lat)+\"_\"+str(lon)+'.csv',sep=';',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define location files\n",
    "pathOfLocationFile = 'location.csv'\n",
    "# Define paths for Zarr datasets\n",
    "agera5Tmax = \"s3://climate-action-datalake/zone=raw/source=agera5/variable=airTemperatureMax.zarr/\"\n",
    "agera5Tmin = \"s3://climate-action-datalake/zone=raw/source=agera5/variable=airTemperatureMin.zarr/\"\n",
    "chirpsPrecipitation = \"s3://climate-action-datalake/zone=raw/source=chirps/variable=precipitation.zarr/\"\n",
    "# Define date range\n",
    "startDt = '2010-01-01'\n",
    "endDt = '2010-01-31'\n",
    "# S3 credentials\n",
    "s3Key = 'key'\n",
    "s3Secret = 'secret'\n",
    "# Generate date range\n",
    "rangeOfDates = pd.date_range(start=startDt,end=endDt)\n",
    "# Initialize S3FileSystem object\n",
    "s3 = s3fs.S3FileSystem(key = s3Key\n",
    "                       ,secret = s3Secret)\n",
    "# Read location data from CSV file\n",
    "locationDf = pd.read_csv(pathOfLocationFile,sep=';')\n",
    "# Extract column names from the location DataFrame\n",
    "colDfNames = locationDf.columns\n",
    "# Set the number of partitions for Dask DataFrame\n",
    "npartitions = 10\n",
    "# Create a Dask DataFrame from the location DataFrame\n",
    "locationDD = dd.from_pandas(locationDf,npartitions=npartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progess = ProgressBar()  \n",
    "with progess:\n",
    "    # Use map_partitions to apply the generateCSVLocationVariables function to each partition for generating CSV file\n",
    "    locationDD.map_partitions(lambda \n",
    "                              df: df.apply(lambda loc: generateCSVLocationVariables(loc[colDfNames[0]],\n",
    "                                                          loc[colDfNames[1]]),axis = 1 )).compute(scheduler='processes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
